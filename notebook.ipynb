{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = Path(\"original\")\n",
    "modified_path = Path(\"modified\")\n",
    "session = rt.InferenceSession(\"models/minimal.onnx\")\n",
    "\n",
    "if not original_path.exists():\n",
    "    raise LookupError()\n",
    "\n",
    "if not modified_path.exists():\n",
    "    shutil.copytree(original_path, modified_path)\n",
    "\n",
    "recordings: list[tuple[str, pd.DataFrame]] = []\n",
    "\n",
    "for original_csv_path in sorted(original_path.glob(\"*.csv\")):\n",
    "    name = Path(original_csv_path).name[:-4]\n",
    "    names = (\"image_id\", \"forward\", \"steering\")\n",
    "\n",
    "    original_df = pd.read_csv(original_csv_path, header=None, names=names)\n",
    "    modified_df = pd.read_csv(modified_path / f\"{name}.csv\", names=names)\n",
    "\n",
    "    original_df[\"modified_steering\"] = modified_df[\"steering\"]\n",
    "\n",
    "    original_df[\"image\"] = original_df[\"image_id\"].apply(\n",
    "        lambda image_id: cv2.imread(str(original_path / name / f\"{image_id:04}.jpg\"))\n",
    "    )\n",
    "\n",
    "    def preprocess(img):\n",
    "        def region_of_interest(image):\n",
    "            height, width = image.shape[:2]\n",
    "            # Define the trapezoid vertices\n",
    "            vertices = np.array(\n",
    "                [\n",
    "                    [\n",
    "                        (0, height),  # Bottom-left\n",
    "                        (width, height),  # Bottom-right\n",
    "                        (width * 0.6, height * 0.4),  # Top-right\n",
    "                        (width * 0.4, height * 0.4),\n",
    "                    ]  # Top-left\n",
    "                ],\n",
    "                dtype=np.int32,\n",
    "            )\n",
    "            mask = np.zeros_like(image)\n",
    "            cv2.fillPoly(mask, vertices, 255)\n",
    "            masked_image = cv2.bitwise_and(image, mask)\n",
    "            return masked_image\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        canny = cv2.Canny(blur, 60, 100)\n",
    "        dilated = cv2.dilate(canny, kernel=(5, 5))\n",
    "\n",
    "        masked = region_of_interest(dilated)\n",
    "        normalized = masked / 255\n",
    "        return np.expand_dims(normalized.astype(np.float32), axis=-1)[np.newaxis]\n",
    "\n",
    "    def postprocess(detections: np.ndarray) -> np.ndarray:\n",
    "        return np.array([0, detections[0, 0]], np.float32)\n",
    "\n",
    "    def predict(img: np.ndarray) -> np.ndarray:\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        inputs = preprocess(img)\n",
    "\n",
    "        assert inputs.dtype == np.float32\n",
    "        assert inputs.shape == (1, 224, 224, 1)\n",
    "        detections = session.run(None, {input_name: inputs})[0]\n",
    "        outputs = postprocess(detections)\n",
    "\n",
    "        assert outputs.dtype == np.float32\n",
    "        assert outputs.shape == (2,)\n",
    "        assert outputs.max() < 1.0\n",
    "        assert outputs.min() > -1.0\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    original_df[\"prediction\"] = original_df[\"image\"].apply(predict)\n",
    "\n",
    "    recordings.append((name, original_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     name, recording \u001b[38;5;241m=\u001b[39m recordings[recording_index \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(recordings)]\n\u001b[0;32m---> 13\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mrecording\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mframe_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     img \u001b[38;5;241m=\u001b[39m frame[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m     image_id \u001b[38;5;241m=\u001b[39m frame[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Controls\n",
    "# Playback: SPACE, J, K\n",
    "# Modify label: H, L\n",
    "# Close and save: Q\n",
    "\n",
    "\n",
    "recording_index = 0\n",
    "frame_index = 0\n",
    "is_pause = True\n",
    "\n",
    "while True:\n",
    "    name, recording = recordings[recording_index % len(recordings)]\n",
    "    frame = recording.iloc[frame_index]\n",
    "\n",
    "    img = frame[\"image\"]\n",
    "    image_id = frame[\"image_id\"]\n",
    "    original_steering = frame[\"steering\"]\n",
    "    modified_steering = frame[\"modified_steering\"]\n",
    "    predicted_steering = frame[\"prediction\"][1] if \"prediction\" in frame else 0\n",
    "\n",
    "    img = cv2.resize(img, np.multiply(img.shape[:-1][::-1], 4))\n",
    "\n",
    "    def format_steering(value):\n",
    "        return f\"{'0' if value == 0 else 'L' if value > 0 else 'R'}{abs(value):.3f}\"\n",
    "\n",
    "    img = cv2.putText(\n",
    "        img,\n",
    "        f\"{name}/{image_id:04}, O: {format_steering(original_steering)}, M: {format_steering(modified_steering)}, P: {format_steering(predicted_steering)}\",\n",
    "        (16, 48),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        (0, 255, 0),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    center = np.divide(img.shape[:-1], 2).astype(int)\n",
    "    cv2.line(\n",
    "        img,\n",
    "        center - (0, 8),\n",
    "        center - (int(original_steering * img.shape[1] / 2), 8),\n",
    "        (255, 0, 0),\n",
    "        2,\n",
    "    )\n",
    "    cv2.line(\n",
    "        img,\n",
    "        center,\n",
    "        center - (int(modified_steering * img.shape[1] / 2), 0),\n",
    "        (0, 255, 0),\n",
    "        2,\n",
    "    )\n",
    "    cv2.line(\n",
    "        img,\n",
    "        center - (0, -8),\n",
    "        center - (int(predicted_steering * img.shape[1] / 2), -8),\n",
    "        (0, 0, 255),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    cv2.imshow(\"Dataset\", img)\n",
    "\n",
    "    if not is_pause:\n",
    "        if frame_index + 1 >= len(recording):\n",
    "            recording_index += 1\n",
    "            frame_index = 0\n",
    "        else:\n",
    "            frame_index += 1\n",
    "\n",
    "    key = cv2.waitKey(30) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    elif key == ord(\" \"):\n",
    "        is_pause = not is_pause\n",
    "    elif key == ord(\"k\"):\n",
    "        if frame_index + 1 >= len(recording):\n",
    "            recording_index += 1\n",
    "            frame_index = 0\n",
    "        else:\n",
    "            frame_index += 1\n",
    "    elif key == ord(\"j\"):\n",
    "        if frame_index - 1 < 0:\n",
    "            recording_index -= 1\n",
    "            frame_index = len(recordings[recording_index][1]) - 1\n",
    "        else:\n",
    "            frame_index -= 1\n",
    "    elif key == ord(\"l\"):\n",
    "        recording.at[frame_index, \"modified_steering\"] = max(\n",
    "            np.round(modified_steering - 0.1, 1), -1\n",
    "        )\n",
    "    elif key == ord(\"h\"):\n",
    "        recording.at[frame_index, \"modified_steering\"] = min(\n",
    "            np.round(modified_steering + 0.1, 1), 1\n",
    "        )\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for name, recording in recordings:\n",
    "    recording[[\"image_id\", \"forward\", \"modified_steering\"]].to_csv(\n",
    "        modified_path / f\"{name}.csv\", index=False, header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_X = np.array([tf.image.flip_left_right(x) for x in X])\n",
    "all_X = np.concatenate([flipped_X, X])[:, 56:]\n",
    "\n",
    "flipped_y = y * (1, -1)\n",
    "all_y = np.concatenate([flipped_y, y])\n",
    "\n",
    "augmentation = keras.Sequential(\n",
    "    [keras.layers.RandomBrightness(0.2), keras.layers.RandomContrast(0.2)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
