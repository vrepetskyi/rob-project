{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_path = Path(\"original\")\n",
    "modified_path = Path(\"modified\")\n",
    "session = rt.InferenceSession(\"models/minimal.onnx\")\n",
    "\n",
    "if not original_path.exists():\n",
    "    raise LookupError()\n",
    "\n",
    "if not modified_path.exists():\n",
    "    shutil.copytree(original_path, modified_path)\n",
    "\n",
    "recordings: list[tuple[str, pd.DataFrame]] = []\n",
    "\n",
    "for original_csv_path in sorted(original_path.glob(\"*.csv\")):\n",
    "    name = Path(original_csv_path).name[:-4]\n",
    "    names = (\"image_id\", \"forward\", \"steering\")\n",
    "\n",
    "    original_df = pd.read_csv(original_csv_path, header=None, names=names)\n",
    "    modified_df = pd.read_csv(modified_path / f\"{name}.csv\", names=names)\n",
    "\n",
    "    original_df[\"modified_steering\"] = modified_df[\"steering\"]\n",
    "\n",
    "    original_df[\"image\"] = original_df[\"image_id\"].apply(\n",
    "        lambda image_id: cv2.imread(str(original_path / name / f\"{image_id:04}.jpg\"))\n",
    "    )\n",
    "\n",
    "    def preprocess(img):\n",
    "        def region_of_interest(image):\n",
    "            height, width = image.shape[:2]\n",
    "            # Define the trapezoid vertices\n",
    "            vertices = np.array(\n",
    "                [\n",
    "                    [\n",
    "                        (0, height),  # Bottom-left\n",
    "                        (width, height),  # Bottom-right\n",
    "                        (width * 0.6, height * 0.4),  # Top-right\n",
    "                        (width * 0.4, height * 0.4),\n",
    "                    ]  # Top-left\n",
    "                ],\n",
    "                dtype=np.int32,\n",
    "            )\n",
    "            mask = np.zeros_like(image)\n",
    "            cv2.fillPoly(mask, vertices, 255)\n",
    "            masked_image = cv2.bitwise_and(image, mask)\n",
    "            return masked_image\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        canny = cv2.Canny(blur, 60, 100)\n",
    "        dilated = cv2.dilate(canny, kernel=(5, 5))\n",
    "\n",
    "        masked = region_of_interest(dilated)\n",
    "        normalized = masked / 255\n",
    "        return np.expand_dims(normalized.astype(np.float32), axis=-1)[np.newaxis]\n",
    "\n",
    "    def postprocess(detections: np.ndarray) -> np.ndarray:\n",
    "        return np.array([0, detections[0, 0]], np.float32)\n",
    "\n",
    "    def predict(img: np.ndarray) -> np.ndarray:\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        inputs = preprocess(img)\n",
    "\n",
    "        assert inputs.dtype == np.float32\n",
    "        assert inputs.shape == (1, 224, 224, 1)\n",
    "        detections = session.run(None, {input_name: inputs})[0]\n",
    "        outputs = postprocess(detections)\n",
    "\n",
    "        assert outputs.dtype == np.float32\n",
    "        assert outputs.shape == (2,)\n",
    "        assert outputs.max() < 1.0\n",
    "        assert outputs.min() > -1.0\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    original_df[\"prediction\"] = original_df[\"image\"].apply(predict)\n",
    "\n",
    "    recordings.append((name, original_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls\n",
    "# Playback: SPACE, J, K\n",
    "# Modify label: H, L\n",
    "# Close and save: Q\n",
    "\n",
    "\n",
    "recording_index = 0\n",
    "frame_index = 0\n",
    "is_pause = True\n",
    "\n",
    "while True:\n",
    "    name, recording = recordings[recording_index % len(recordings)]\n",
    "    frame = recording.iloc[frame_index]\n",
    "\n",
    "    img = frame[\"image\"]\n",
    "    image_id = frame[\"image_id\"]\n",
    "    original_steering = frame[\"steering\"]\n",
    "    modified_steering = frame[\"modified_steering\"]\n",
    "    predicted_steering = frame[\"prediction\"][1] if \"prediction\" in frame else 0\n",
    "\n",
    "    img = cv2.resize(img, np.multiply(img.shape[:-1][::-1], 4))\n",
    "\n",
    "    def format_steering(value):\n",
    "        return f\"{'0' if value == 0 else 'L' if value > 0 else 'R'}{abs(value):.3f}\"\n",
    "\n",
    "    img = cv2.putText(\n",
    "        img,\n",
    "        f\"{name}/{image_id:04}, O: {format_steering(original_steering)}, M: {format_steering(modified_steering)}, P: {format_steering(predicted_steering)}\",\n",
    "        (16, 48),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        (0, 255, 0),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    center = np.divide(img.shape[:-1], 2).astype(int)\n",
    "    cv2.line(\n",
    "        img,\n",
    "        center - (0, 8),\n",
    "        center - (int(original_steering * img.shape[1] / 2), 8),\n",
    "        (255, 0, 0),\n",
    "        2,\n",
    "    )\n",
    "    cv2.line(\n",
    "        img,\n",
    "        center,\n",
    "        center - (int(modified_steering * img.shape[1] / 2), 0),\n",
    "        (0, 255, 0),\n",
    "        2,\n",
    "    )\n",
    "    cv2.line(\n",
    "        img,\n",
    "        center - (0, -8),\n",
    "        center - (int(predicted_steering * img.shape[1] / 2), -8),\n",
    "        (0, 0, 255),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "    cv2.imshow(\"Dataset\", img)\n",
    "\n",
    "    if not is_pause:\n",
    "        if frame_index + 1 == len(recording):\n",
    "            recording_index += 1\n",
    "            frame_index = 0\n",
    "        else:\n",
    "            frame_index += 1\n",
    "\n",
    "    key = cv2.waitKey(30) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    elif key == ord(\" \"):\n",
    "        is_pause = not is_pause\n",
    "    elif key == ord(\"k\"):\n",
    "        frame_index += 1\n",
    "    elif key == ord(\"j\"):\n",
    "        frame_index -= 1\n",
    "    elif key == ord(\"l\"):\n",
    "        recording.at[frame_index, \"modified_steering\"] = max(\n",
    "            np.round(modified_steering - 0.1, 1), -1\n",
    "        )\n",
    "    elif key == ord(\"h\"):\n",
    "        recording.at[frame_index, \"modified_steering\"] = min(\n",
    "            np.round(modified_steering + 0.1, 1), 1\n",
    "        )\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for name, recording in recordings:\n",
    "    recording[[\"image_id\", \"forward\", \"modified_steering\"]].to_csv(\n",
    "        modified_path / f\"{name}.csv\", index=False, header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_X = np.array([tf.image.flip_left_right(x) for x in X])\n",
    "all_X = np.concatenate([flipped_X, X])[:, 56:]\n",
    "\n",
    "flipped_y = y * (1, -1)\n",
    "all_y = np.concatenate([flipped_y, y])\n",
    "\n",
    "augmentation = keras.Sequential(\n",
    "    [keras.layers.RandomBrightness(0.2), keras.layers.RandomContrast(0.2)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
